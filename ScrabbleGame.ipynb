{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SmjQySk_kbU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjMoLRZQ_6Gs",
        "outputId": "1b2188d0-e5c6-4c76-98d2-bde480875068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n",
        "test=pd.read_csv(\"/content/drive/MyDrive/test.csv\")\n",
        "games=pd.read_csv(\"/content/drive/MyDrive/games.csv\")\n",
        "turns=pd.read_csv(\"/content/drive/MyDrive/turns.csv\")\n",
        "sub=pd.read_csv(\"/content/submission.csv\")"
      ],
      "metadata": {
        "id": "n17eJQAI_76K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "202acaad-286c-460a-d5a2-772495239fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e7a403b15153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/games.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mturns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/turns.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/submission.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "WantQZoWRxQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub.info()"
      ],
      "metadata": {
        "id": "9ulvOYvOkeNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "vfWOwCSbDGtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "metadata": {
        "id": "XGVHVWVOD7Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "games.info()"
      ],
      "metadata": {
        "id": "qZz_z0hmD7K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "turns.info()"
      ],
      "metadata": {
        "id": "ScA4dMPTD7OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.rename(columns=str.lower)\n",
        "test  = test.rename(columns=str.lower)\n",
        "turns = turns.rename(columns=str.lower)\n",
        "games = games.rename(columns=str.lower)"
      ],
      "metadata": {
        "id": "tVrfXRUaES3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brief_df = pd.concat([train, test], axis=0)\n",
        "brief_df = brief_df.sort_values([\"game_id\"])\n",
        "bots = [\"BetterBot\", \"STEEBot\", \"HastyBot\"]\n",
        "\n",
        "\n",
        "user_df = brief_df[~brief_df[\"nickname\"].isin(bots)]\n",
        "user_df = user_df.rename(\n",
        "    columns={\"nickname\": \"user_name\", \"score\": \"user_score\", \"rating\": \"user_rating\"}\n",
        ")\n",
        "bot_df = brief_df[brief_df[\"nickname\"].isin(bots)]\n",
        "\n",
        "bot_df = bot_df.rename(\n",
        "    columns={\"nickname\": \"bot_name\", \"score\": \"bot_score\", \"rating\": \"bot_rating\"}\n",
        ")\n",
        "\n",
        "main_df = pd.merge(user_df, bot_df, on=\"game_id\")\n",
        "main_df.head()"
      ],
      "metadata": {
        "id": "TCxqwGhtEVE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df.info()"
      ],
      "metadata": {
        "id": "tQAwiM1hEdvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "main_df[\"user_freq\"] = main_df.groupby(\"user_name\")[\"user_name\"].transform(\"count\")\n",
        "encode_bots = LabelEncoder()\n",
        "main_df[\"bot_name\"] = encode_bots.fit_transform(main_df[\"bot_name\"])\n",
        "main_df.head()"
      ],
      "metadata": {
        "id": "24EfNbwJEdx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_cols = main_df.columns[main_df.isnull().any()].tolist()\n",
        "print(f'These labels have missing data that needs to be cleaned: {missing_cols} ')"
      ],
      "metadata": {
        "id": "WkFpC5peEdzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = main_df[~main_df['user_rating'].isna()].reset_index(drop=True)\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "FYNZ7n_oEd3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df  = main_df[main_df['user_rating'].isna()].reset_index(drop=True)\n",
        "test_df.head()"
      ],
      "metadata": {
        "id": "ZtgTNzIVGCHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df[main_df.duplicated()].shape[0]"
      ],
      "metadata": {
        "id": "piPfvF_xGCW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_score = train.sort_values(by='score', ascending=False)[:30]\n",
        "figure = plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=top_score.nickname, y=top_score.score)\n",
        "plt.xticks()\n",
        "plt.ylabel('Scrabble Scores')\n",
        "plt.xlabel('Competitor Nickname')\n",
        "plt.title('Scrabble Competitors by Scores')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qDjbbY1uGiWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = games.corr(method='pearson')\n",
        "sns.heatmap(corr)"
      ],
      "metadata": {
        "id": "PL1CZ2NqGiYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "games[\"rating_mode\"].value_counts().plot.bar(figsize=(8, 6), color=['#f5803d', '#f5005a'], title='Scrabble Rating Mode');"
      ],
      "metadata": {
        "id": "PSanHTVBGia1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize = (25, 5))\n",
        "ax = axes.flatten()\n",
        "sns.histplot(ax = axes[0], x = main_df[\"user_score\"], bins = 20, kde = True, color = \"#f5803d\").set(title = \"Distribution of user_score variable\");\n",
        "sns.histplot(ax = axes[1], x = main_df[\"bot_score\"], bins = 20, kde = True, color = \"#f5483a\").set(title = \"Distribution of bot_score variable\");\n",
        "sns.histplot(ax = axes[2], x = main_df[\"bot_rating\"], bins = 20, kde = True, color = \"#f5003d\").set(title = \"Distribution of bot_rating variable\");"
      ],
      "metadata": {
        "id": "-XLAze5yGidF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize = (30, 6))\n",
        "axes = axes.flatten()\n",
        "sns.scatterplot(ax = axes[0], x = \"user_score\", y = \"bot_score\", data = main_df, color = \"#f5483a\"\n",
        "                ).set(title = \"Relationship between user_score VS bot_score\");\n",
        "sns.scatterplot(ax = axes[1], x = \"bot_score\", y = \"bot_rating\", data = main_df,\n",
        "                color = \"#f5003d\").set(title = \"Relationship between bot_score VS bot_rating\")\n",
        ""
      ],
      "metadata": {
        "id": "-6tlicZLGifO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import  LinearRegression, Ridge,Lasso\n",
        "from sklearn.tree import  DecisionTreeRegressor\n",
        "from sklearn.ensemble import  RandomForestRegressor,GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import lightgbm as lgb\n",
        "model_dict = {\n",
        "    \"linear\": LinearRegression(),\n",
        "    \"ridge\": Ridge(),\n",
        "    \"lasso\": Lasso(),\n",
        "    \"decision_tree\": DecisionTreeRegressor(),\n",
        "    \"random_forest\": RandomForestRegressor(),\n",
        "    \"gradient_boosting\": GradientBoostingRegressor(),\n",
        "    \"neural_network\": MLPRegressor(),\n",
        "    \"lgb\": lgb.LGBMRegressor(),\n",
        "}"
      ],
      "metadata": {
        "id": "wsj4NUKUGiix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scores(model_dict, X, y, nfolds=5):\n",
        "    \"\"\"\n",
        "    This function computes the cross-validated R^2 and RMSE scores\n",
        "    for each model in model_dict on the provided training data X and y.\n",
        "\n",
        "    Args:\n",
        "        model_dict (dict): A dictionary containing the models to be evaluated, with keys as model names and values as the initialized model objects.\n",
        "        X (pandas.DataFrame): The training data on which to evaluate the models.\n",
        "        y (pandas.DataFrame): The target variable for the training data.\n",
        "        nfolds (int, optional): The number of folds to use for cross-validation. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A dataframe containing the mean R^2 and RMSE scores for each model, computed using cross-validation.\n",
        "    \"\"\"\n",
        "    df_score_details = {\n",
        "        \"model\": [],\n",
        "        \"(R2)\": [],\n",
        "        \"(RMSE)\": [],\n",
        "        \"(MAE)\": [],\n",
        "    }\n",
        "    for model_key in model_dict.keys():\n",
        "        val_r2_scores = []\n",
        "        val_rmse_scores = []\n",
        "        val_mae_scores = []\n",
        "        kf = KFold(n_splits=nfolds)\n",
        "        start = time.time()\n",
        "        # nfolds\n",
        "        for train_index, val_index in kf.split(X):\n",
        "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "            # model\n",
        "            model_cls = model_dict[model_key] # model\n",
        "            model = model_cls\n",
        "            model.fit(X_train, y_train) # X_train\n",
        "            # validation_data model\n",
        "            val_preds = model.predict(X_val).reshape(-1) # X_val\n",
        "            val_r2_scores.append(r2_score(y_val, val_preds))\n",
        "            val_rmse_scores.append(mean_squared_error(y_val, val_preds, squared=False)) # RMSE\n",
        "            val_mae_scores.append(mean_absolute_error(y_val, val_preds)) # MAE\n",
        "        df_score_details[\"model\"].append(model_key)\n",
        "        df_score_details[\"(R2)\"].append(np.mean(val_r2_scores))\n",
        "        df_score_details[\"(RMSE)\"].append(np.mean(val_rmse_scores))\n",
        "        df_score_details[\"(MAE)\"].append(np.mean(val_mae_scores))\n",
        "        elapsed_time = time.time() - start\n",
        "        print(\"-------------------------\")\n",
        "        print(f\"model{model_key}: {df_score_details}\")\n",
        "        print(f\"{model_key} finished in {elapsed_time:.2f} seconds\")\n",
        "        print(\"-------------------------\")\n",
        "    df_score = pd.DataFrame(df_score_details)\n",
        "    return df_score"
      ],
      "metadata": {
        "id": "Rh-SheGGIj33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "import time\n",
        "X_train = train_df.drop([\"user_name\", \"user_rating\"], axis=1)\n",
        "y_train = train_df[\"user_rating\"].copy()\n",
        "X_test = test_df.drop([\"user_name\", \"user_rating\"], axis=1)\n",
        "# CV\n",
        "df_score = get_scores(model_dict, X_train, y_train, nfolds=2)"
      ],
      "metadata": {
        "id": "A8cPkhDkJARk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_score.sort_values(\"(RMSE)\")"
      ],
      "metadata": {
        "id": "l1B4dsfoJAUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "test_df[\"user_rating\"] = model.predict(\n",
        "    test_df.drop([\"user_name\", \"user_rating\"], axis=1)\n",
        ")\n",
        "final_sub = test_df[[\"game_id\", \"user_rating\"]]\n",
        "final_sub = final_sub.rename(columns={\"user_rating\": \"rating\"})\n",
        "print(final_sub.head())\n",
        "final_sub.to_csv(\"submission.csv\", index=False)\n",
        "print('Submission successful!')"
      ],
      "metadata": {
        "id": "dp-BVEOpJAXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_sub"
      ],
      "metadata": {
        "id": "WEhB4PTBjQVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGCgnXXEjQdo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}